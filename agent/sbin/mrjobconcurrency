#!/usr/bin/env node
/* vim: set ft=javascript: */

/*
 * mrjobconcurrency: given a marlin agent log file on stdin and the path to a
 * file mapping jobids to job names, produce a GNUplot file that will plot each
 * job's concurrency over time based on the data in the log file.  This is
 * useful for visualizing Marlin zone allocation.
 */

var mod_assertplus = require('assert-plus');
var mod_cmdutil = require('cmdutil');
var mod_extsprintf = require('extsprintf');
var mod_fs = require('fs');
var mod_getopt = require('posix-getopt');
var mod_jsprim = require('jsprim');
var mod_lstream = require('lstream');
var mod_stream = require('stream');
var mod_util = require('util');
var mod_vasync = require('vasync');
var mod_vstream = require('vstream');
var mod_vstream_json_parser = require('vstream-json-parser');
var VError = require('verror');

var sprintf = mod_extsprintf.sprintf;

var UUID_STRLEN = 36;
var showIdleZonesAsAssigned = false;

function main()
{
	var parser, option, jobsfile;
	var jobinfo, logreader;

	mod_cmdutil.configure({
	    'synopses': [ 'JOBS_FILE' ],
	    'usageMessage': 'Report on zone concurrency based on the ' +
		'contents of an agent\'s log file.'
	});

	parser = new mod_getopt.BasicParser('', process.argv);
	while ((option = parser.getopt()) !== undefined) {
		switch (option.option) {
		default:
			/* error message already emitted. */
			mod_cmdutil.usage();
			break;
		}
	}

	if (process.argv.length != parser.optind() + 1) {
		mod_cmdutil.usage();
	}

	if (process.stdin.isTTY) {
		mod_cmdutil.warn('warn: reading agent log from tty on stdin');
	}

	jobsfile = process.argv[parser.optind()];

	mjcLoadJobInfo(jobsfile, function (err, info) {
		if (err) {
			mod_cmdutil.fail(err);
		}

		jobinfo = info;
		logreader = new mjcLogReader({
		    'jobs': jobinfo,
		    'showIdleZonesAsAssigned': showIdleZonesAsAssigned
		});

		process.stdin.pipe(logreader);

		logreader.on('error', function (err2) {
			mod_cmdutil.fail(err2);
		});

		logreader.on('warn', function (context, kind, err2) {
			mod_cmdutil.warn(err2);
			console.error('at %s', context.label());
		});

		logreader.pipe(process.stdout);
	});

}

/*
 * Given the path to a file containing rows of the form:
 *
 *     jobid   jobName
 *
 * read the file, parse the contents, and invoke "callback" with an object
 * mapping job ids to job objects, each having properties "jobId" and "jobName".
 */
function mjcLoadJobInfo(filename, callback)
{
	var input, opened, failed;
	var jobs, lstream;

	input = mod_fs.createReadStream(filename);
	opened = false;
	input.on('error', function (err) {
		mod_assertplus.ok(!failed);
		failed = true;

		if (!opened) {
			err = new VError(err, 'open "%s"', filename);
		} else {
			err = new VError(err, 'read "%s"', filename);
		}

		callback(err);
	});

	input.on('open', function () { opened = true; });

	lstream = new mod_lstream();
	input.pipe(lstream);

	jobs = {};
	lstream.on('data', function (line) {
		var jobid, jobname;

		if (line.length === 0) {
			/*
			 * Skip blank lines, which typically appear at the end
			 * of files.
			 */
			return;
		}

		jobid = line.substr(0, UUID_STRLEN);
		jobname = line.substr(UUID_STRLEN + 1).trim();
		jobs[jobid] = {
		    'jobId': jobid,
		    'jobName': jobname
		};
	});

	lstream.on('end', function () {
		mod_assertplus.ok(!failed);
		callback(null, jobs);
	});
}

function createOneOffTransform(args)
{
	var rv, options;

	mod_assertplus.object(args, 'args');
	mod_assertplus.func(args.transform, 'args.transform');
	mod_assertplus.optionalFunc(args.flush, 'args.flush');
	mod_assertplus.optionalObject(args.streamOptions, 'args.streamOptions');

	options = args.hasOwnProperty('streamOptions') ?
	    args['streamOptions'] : undefined;

	rv = new mod_stream.Transform(options);
	rv._transform = args['transform'];
	if (args.flush) {
		rv._flush = args['flush'];
	}

	return (rv);
}

/*
 * This LogReader is a Writable stream that accepts data directly from a Marlin
 * agent log and keeps track of concurrency for each job.  This class just wraps
 * a pipeline of streams.  The guts are handled in mjcLogRecordReader.
 */
function mjcLogReader(args)
{
	var self = this;
	var reader, streams;

	mod_assertplus.object(args, 'args');
	mod_assertplus.object(args.jobs, 'args.jobs');
	mod_assertplus.bool(args.showIdleZonesAsAssigned,
	    'args.showIdleZonesAsAssigned');

	streams = [];

	streams.push(new mod_lstream());
	streams.push(new mod_vstream_json_parser());

	reader = new mjcLogRecordReader(args);
	streams.push(reader);

	reader.on('warn', function () {
		var warnargs = Array.prototype.slice.call(arguments);
		warnargs.unshift('warn');
		self.emit.apply(self, warnargs);
	});

	mod_vstream.PipelineStream.call(this, {
	    'streams': streams
	});
}

mod_util.inherits(mjcLogReader, mod_vstream.PipelineStream);

function mjcLogRecordReader(args)
{
	mod_assertplus.object(args, 'args');
	mod_assertplus.object(args.jobs, 'args.jobs');
	mod_assertplus.bool(args.showIdleZonesAsAssigned,
	    'args.showIdleZonesAsAssigned');

	this.mrr_time = null;		/* last seen timestamp */
	this.mrr_countbyseries = {};	/* list of data points, by series */
	this.mrr_jobs = args.jobs;	/* jobid -> job details */
	this.mrr_events = {		/* messages to act on */
	    'stream terminated': true,
	    'created stream': true
	};
	this.mrr_showidle = args.showIdleZonesAsAssigned;

	if (!this.mrr_showidle) {
		this.mrr_events['stream idle'] = true;
		this.mrr_events['taking idle stream for new task'] = true;
	}

	mod_stream.Transform.call(this, {
	    'objectMode': true
	});
	mod_vstream.wrapTransform(this);
}

mod_util.inherits(mjcLogRecordReader, mod_stream.Transform);

mjcLogRecordReader.prototype._transform = function (entry, _, callback)
{
	var time, count;

	/*
	 * Our analysis wholly depends on getting log entries in chronological
	 * order.  It shouldn't be possible for entries to arrive out of order,
	 * or even missing timestamps, unless the clock went backwards on this
	 * system.  More likely, if this happened, the user gave us garbage, or
	 * cat'ed multiple files together in the wrong order, and it's better to
	 * check for this and report a fatal error than produce garbage.
	 */
	if (!entry.hasOwnProperty('time')) {
		this.fatal(callback, new VError('missing "time" field'));
		return;
	}

	time = Date.parse(entry['time']);
	if (isNaN(time)) {
		this.fatal(callback, new VError('invalid "time" field'));
		return;
	}

	if (this.mrr_time !== null && this.mrr_time > time) {
		this.fatal(callback,
		    new VError('records found out of chronological order'));
		return;
	}

	this.mrr_time = time;

	if (entry['msg'] == 'current zone states') {
		this.emitPoint({
		    'p_time': time,
		    'p_series': 'nresetting',
		    'p_count': entry['nresetting']
		});
	} else if (this.mrr_events.hasOwnProperty(entry['msg']) &&
	    this.mrr_jobs.hasOwnProperty(entry['job'])) {
		count = entry['group_concurrency'];

		if (!this.mrr_showidle) {
			count -= entry['group_nidle'];
		}

		this.emitPoint({
		    'p_time': time,
		    'p_series': entry['job'],
		    'p_count': count
		});
	}

	setImmediate(callback);
};

mjcLogRecordReader.prototype.fatal = function (func, err)
{
	/*
	 * vsWarn() causes us to emit a useful message to stderr that includes
	 * information about the input that we're processing.  Emitting 'error'
	 * causes the pipeline to stop.
	 */
	this.vsWarn(err, err.message);
	this.emit('error', err);
};

mjcLogRecordReader.prototype.emitPoint = function (point)
{
	var points;

	/*
	 * It would be nice if we could stream our output rather than buffering
	 * everything, but it's not clear if GNUplot supports interleaved points
	 * in the way we would need in order to do that.
	 */
	if (!this.mrr_countbyseries.hasOwnProperty(point.p_series)) {
		/*
		 * Insert a point at zero just before the first point we read
		 * because otherwise GNUplot won't know that the value started
		 * at zero.
		 */
		this.mrr_countbyseries[point.p_series] = [ {
		    'p_time': point.p_time - 1,
		    'p_series': point.p_series,
		    'p_count': 0
		} ];
	}

	/*
	 * If we already have a point for this timestamp, drop that one.  (We'll
	 * only save the last point for each timestamp.)
	 */
	points = this.mrr_countbyseries[point.p_series];
	if (points.length > 0 &&
	    points[points.length - 1].p_time == point.p_time) {
		points.pop();
	}

	points.push(point);
};

mjcLogRecordReader.prototype._flush = function (callback)
{
	var self = this;
	var seriescmds, earliest, latest;

	self.push([
	    '#',
	    '# This GNUplot control and data file was generated automatically ',
	    '# by the "mrjobconcurrency" tool.  You can use it to create a ',
	    '# graph as a PNG image using:',
	    '#',
	    '#     gnuplot < this_file > graph.png',
	    '#',
	    '',
	    'set terminal png size 1200,600',
	    'set title "Job Concurrency"',
	    '',
	    '# Configure plots to use the x-axis as time.',
	    'set xdata time;',
	    'set timefmt "%Y-%m-%dT%H:%M:%SZ',
	    'set format x "%m/%d\\n%H:%M:%.3SZ";',
	    '',
	    '# Add 25% padding to the top of the graph.',
	    'set offsets graph 0, 0, 0.25, 0;',
	    '',
	    '# The y-axis should always start at zero.',
	    'set yrange [0:*]',
	    'set ylabel "Number of zones"',
	    'set ytics',
	    '',
	    ''
	].join('\n'));

	/*
	 * This is going to look pretty odd in the output file, but GNUplot will
	 * interpret each "-" as "read the next block from stdin".  So we emit
	 * each of the jobs' "plot" commands in order, _then_ we emit all the
	 * data blocks in order.
	 *
	 * In this pass, we keep track of the earliest and latest data points in
	 * each of the job series.  We'll prune data points from special series
	 * to fit within this range.
	 */
	earliest = null;
	latest = null;
	mod_jsprim.forEachKey(this.mrr_countbyseries,
	    function (series, points) {
		self.push(sprintf('# Series "%s"\n', series));

		if (series != 'nresetting') {
			earliest = earliest === null ?
			    points[0].p_time :
			    Math.min(earliest, points[0].p_time);
			latest = latest === null ?
			    points[points.length - 1].p_time :
			    Math.max(latest, points[points.length - 1].p_time);
		}
	    });

	/*
	 * Now, trim our special series to remove data points outside the range.
	 * (We'll keep up to one data point outside the range on either end to
	 * frame the graph.)
	 */
	if (this.mrr_countbyseries.hasOwnProperty('nresetting')) {
		var ps, pi;

		ps = this.mrr_countbyseries['nresetting'];
		for (pi = 0; pi < ps.length; pi++) {
			if (ps[pi].p_time >= earliest) {
				break;
			}
		}

		if (pi > 0) {
			ps.splice(0, pi - 1);
		}

		for (pi = ps.length - 1; pi >= 0; pi--) {
			if (ps[pi].p_time <= latest) {
				break;
			}
		}

		ps.splice(pi + 2, ps.length - 1 - pi);
	}

	self.push('plot \\\n');
	seriescmds = [
	    '    "-" using 1:2 with steps title "zones resetting" linecolor ' +
	        '"lightgrey"'
	];

	mod_jsprim.forEachKey(this.mrr_countbyseries, function (series) {
		var seriesname;

		if (series == 'nresetting') {
			return;
		}

		seriesname = self.mrr_jobs[series].jobName;
		if (seriesname === '' || seriesname == '-')
			seriesname = series;

		seriescmds.push(
		    sprintf('    "-" using 1:2 with steps title %s',
		    JSON.stringify(seriesname)));
	});

	self.push(seriescmds.join(', \\\n') + '\n');

	if (this.mrr_countbyseries.hasOwnProperty('nresetting')) {
		this.dumpOneSeries(this.mrr_countbyseries['nresetting']);
	}

	mod_jsprim.forEachKey(this.mrr_countbyseries,
	    function (series, points) {
		if (series != 'nresetting') {
			self.dumpOneSeries(points);
		}
	    });

	setImmediate(callback);
};

mjcLogRecordReader.prototype.dumpOneSeries = function (points)
{
	var self = this;

	points.forEach(function (p, i) {
		self.push(sprintf('\t%s %d\n',
		    new Date(p.p_time).toISOString(), p.p_count));
	});

	self.push(sprintf('\te\n'));
};

main();
